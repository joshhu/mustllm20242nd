{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編碼器模型範例\n",
    "這是一個編碼器模型的範例，用於將輸入的序列進行編碼，並將編碼後的結果輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text=\"my bank account\"\n",
    "encoded_input = tokenizer(text, max_length=100,\n",
    "                            add_special_tokens=True, truncation=True,\n",
    "                            padding=True, return_tensors=\"pt\")\n",
    "output = model(**encoded_input)\n",
    "last_hidden_state, pooler_output = output[0], output[1]\n",
    "print(model)\n",
    "print(output[0].shape)\n",
    "print(output[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# 使用 AutoTokenizer 和 AutoModel 替代 BertTokenizer 和 BertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"my bank account\"\n",
    "encoded_input = tokenizer(\n",
    "    text, \n",
    "    max_length=100, \n",
    "    add_special_tokens=True, \n",
    "    truncation=True, \n",
    "    padding=True, \n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "output = model(**encoded_input)\n",
    "\n",
    "# `output` 是 ModelOutput，包含 `last_hidden_state` 和其他屬性\n",
    "last_hidden_state = output.last_hidden_state\n",
    "pooler_output = output.pooler_output if \"pooler_output\" in output else None\n",
    "\n",
    "print(model)\n",
    "print(last_hidden_state.shape)\n",
    "print(last_hidden_state[0])\n",
    "\n",
    "if pooler_output is not None:\n",
    "    print(pooler_output.shape)\n",
    "    print(pooler_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解碼器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2Model\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Yes, Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(last_hidden_states.shape)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 使用 AutoTokenizer 和 AutoModel 替代 GPT2Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModel.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "# 將文本轉換為張量格式\n",
    "inputs = tokenizer(\"Yes, Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "# 模型前向傳播\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 提取最後的隱藏層狀態\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# 印出隱藏層形狀和模型結構\n",
    "print(last_hidden_states.shape)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# 使用 AutoTokenizer 和 AutoModel 替代 GPT2Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 準備輸入文字\n",
    "text = \"The quick brown fox jumps over the lazy dog\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 獲取模型輸出\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# logits 是應用softmax之前的輸出，直接對應於詞彙表的維度\n",
    "logits = outputs.logits\n",
    "\n",
    "# 展示logits的維度\n",
    "# 維度應該是 [批次大小, 序列長度, 詞彙表大小]\n",
    "print(\"Logits shape:\", logits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序列到序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5EncoderModel, T5Tokenizer\n",
    "\n",
    "# 加載模型和分詞器\n",
    "model_name = 'google/mt5-small' # 可以根據需要選擇不同大小的MT5模型\n",
    "model = MT5EncoderModel.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# 使用 AutoModel 和 AutoTokenizer 替代 MT5EncoderModel 和 T5Tokenizer\n",
    "model_name = 'google/mt5-small'  # 可以根據需要選擇不同大小的 MT5 模型\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 印出模型結構\n",
    "print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "galore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
